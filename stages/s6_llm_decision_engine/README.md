# Stage 6: LLM Decision Engine

## ğŸ¤– Overview

This stage implements an LLM (Large Language Model) decision engine that processes PLM output to make intelligent navigation and mission decisions. The system provides autonomous decision-making capabilities for search-and-rescue missions.

## ğŸ—ï¸ Architecture

### Components
- **LLM Integration**: GPT, Mistral, or local model integration
- **Decision Framework**: Structured decision-making pipeline
- **Mission Planning**: Goal-oriented mission execution
- **Navigation Logic**: Path planning and obstacle avoidance
- **Behavior Management**: Adaptive behavior selection
- **Safety Systems**: Emergency protocols and fail-safes

### Key Features
- âœ… AI-powered decision making
- âœ… Mission planning and execution
- âœ… Adaptive navigation strategies
- âœ… Safety and emergency protocols
- âœ… Real-time decision processing
- âœ… Integration with flight controller

## ğŸš€ Quick Start

### Prerequisites
- Stage 1: Quadcopter Simulation
- Stage 2: 3D Map Creation
- Stage 3: Sensor Simulation
- Stage 4: SLAM Engine
- Stage 5: Perception Language Model (PLM)
- Docker Desktop for Mac

### Installation & Running

```bash
# Navigate to Stage 6
cd stages/s6_llm_decision_engine

# Build and run with Docker
docker-compose up --build

# Or run individual components
./scripts/launch_llm_engine.sh
./scripts/launch_mission_planner.sh
./scripts/launch_navigation_ai.sh
```

## ğŸ“ File Structure

```
s6_llm_decision_engine/
â”œâ”€â”€ README.md
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ llm_engine/
â”‚   â”œâ”€â”€ mission_planner/
â”‚   â”œâ”€â”€ navigation_ai/
â”‚   â”œâ”€â”€ behavior_manager/
â”‚   â””â”€â”€ safety_system/
â”œâ”€â”€ launch/
â”‚   â”œâ”€â”€ llm_engine.launch.py
â”‚   â”œâ”€â”€ mission_planner.launch.py
â”‚   â”œâ”€â”€ navigation_ai.launch.py
â”‚   â””â”€â”€ all_ai.launch.py
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ llm_params.yaml
â”‚   â”œâ”€â”€ mission_params.yaml
â”‚   â”œâ”€â”€ navigation_params.yaml
â”‚   â””â”€â”€ behavior_params.yaml
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ launch_llm_engine.sh
â”‚   â”œâ”€â”€ launch_mission_planner.sh
â”‚   â””â”€â”€ test_ai.sh
â””â”€â”€ tests/
    â”œâ”€â”€ test_llm_engine.py
    â”œâ”€â”€ test_mission_planner.py
    â””â”€â”€ test_navigation_ai.py
```

## ğŸ¤– AI Components

### LLM Decision Engine
- **Input**: PLM descriptions, sensor data, mission goals
- **Model**: GPT-4, Mistral, or local LLM
- **Output**: Navigation decisions, behavior commands
- **Performance**: 5 Hz, < 500ms latency
- **Topics**: `/ai/llm/decisions`, `/ai/llm/reasoning`

### Mission Planner
- **Input**: Mission objectives, environment data
- **Features**: Goal decomposition, task planning
- **Output**: Mission plans, waypoint sequences
- **Performance**: 1 Hz, < 1s latency
- **Topics**: `/ai/mission/plan`, `/ai/mission/status`

### Navigation AI
- **Input**: Current pose, obstacles, goals
- **Features**: Path planning, obstacle avoidance
- **Output**: Waypoints, velocity commands
- **Performance**: 10 Hz, < 100ms latency
- **Topics**: `/ai/navigation/waypoints`, `/ai/navigation/commands`

## ğŸ§ª Testing

### Run All Tests
```bash
./scripts/run_tests.sh
```

### Individual Tests
```bash
# Test LLM engine
python3 tests/test_llm_engine.py

# Test mission planner
python3 tests/test_mission_planner.py

# Test navigation AI
python3 tests/test_navigation_ai.py

# Test behavior management
python3 tests/test_behavior_manager.py
```

## ğŸ”§ Configuration

### LLM Parameters
Edit `config/llm_params.yaml`:
```yaml
llm_engine:
  model:
    type: "gpt4"  # or "mistral", "local"
    api_key: "${OPENAI_API_KEY}"
    max_tokens: 500
    temperature: 0.7
  
  prompts:
    navigation: "Given the environment description: {env_desc}, current position: {pos}, and goal: {goal}, what navigation action should the drone take?"
    obstacle_avoidance: "The drone detects {obstacle} at {distance}. What is the safest avoidance maneuver?"
    mission_planning: "For mission objective: {objective}, in environment: {env}, what is the optimal search strategy?"
  
  decision_framework:
    confidence_threshold: 0.8
    fallback_behavior: "hover"
    max_decision_time: 1.0
```

### Mission Parameters
Edit `config/mission_params.yaml`:
```yaml
mission_planner:
  search_patterns:
    grid_search:
      spacing: 2.0
      altitude: 3.0
      coverage: 0.9
    
    spiral_search:
      radius_increment: 1.0
      angle_increment: 45.0
    
    random_search:
      max_distance: 10.0
      min_distance: 1.0
  
  objectives:
    search_rescue:
      priority: "high"
      search_area: "entire_building"
      target_type: "person"
    
    mapping:
      priority: "medium"
      coverage: "complete"
      detail_level: "high"
```

### Navigation Parameters
Edit `config/navigation_params.yaml`:
```yaml
navigation_ai:
  path_planning:
    algorithm: "a_star"
    resolution: 0.5
    safety_margin: 1.0
  
  obstacle_avoidance:
    detection_range: 5.0
    avoidance_distance: 2.0
    emergency_stop_distance: 1.0
  
  behavior:
    max_velocity: 5.0
    max_acceleration: 2.0
    turn_radius: 2.0
```

## ğŸ”„ Integration with Previous Stages

### Input from Stage 5
- Natural language environment descriptions
- Object and obstacle information
- Navigation context and suggestions
- Mission objectives and constraints

### Output for Stage 7
- Navigation waypoints and commands
- Mission execution plans
- Behavior and safety decisions
- Real-time decision reasoning

## ğŸ“Š Performance Metrics

### Target Performance
- **LLM Processing**: 5 Hz, < 500ms latency
- **Mission Planning**: 1 Hz, < 1s latency
- **Navigation AI**: 10 Hz, < 100ms latency
- **Decision Making**: < 200ms per decision
- **Memory Usage**: < 1GB total
- **CPU Usage**: < 30% total

### AI Accuracy Metrics
- **Decision Quality**: 90% optimal choices
- **Path Planning**: 95% successful navigation
- **Obstacle Avoidance**: 99% collision-free
- **Mission Success**: 85% objective completion

## ğŸ¯ Success Criteria

1. **âœ… AI Decision Making**: Intelligent navigation choices
2. **âœ… Mission Planning**: Goal-oriented mission execution
3. **âœ… Safety Systems**: Robust emergency protocols
4. **âœ… Real-time Performance**: Sub-second decision times
5. **âœ… Integration**: Works with Stages 1-5
6. **âœ… Testing**: Comprehensive AI validation
7. **âœ… Documentation**: Complete AI API documentation
8. **âœ… Reliability**: 99% uptime and error recovery

## ğŸš€ Next Stage Preparation

This stage provides:
- **AI-powered decision making** for autonomous flight
- **Mission planning and execution** capabilities
- **Intelligent navigation** and obstacle avoidance
- **Safety and emergency** protocols

Ready for **Stage 7: Navigation Control Loop** where we'll connect the AI decisions to the flight controller for autonomous execution. 